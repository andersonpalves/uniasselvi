# -*- coding: utf-8 -*-
"""AlgoritmoSupervisionado.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wedic-h3PiIV631WX-i28AdwV-LtnC-y

# Projeto Interativo: Classifica√ß√£o de Vinhos com Scikit-Learn
"""

# Importar bibliotecas
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

"""## Carregar e explorar o dataset"""

wine = load_wine()
df = pd.DataFrame(wine.data, columns=wine.feature_names)
df['target'] = wine.target
df['class'] = df['target'].apply(lambda x: wine.target_names[x])

df.head()

"""## Distribui√ß√£o das classes"""

sns.countplot(x='class', data=df)
plt.title('Distribui√ß√£o das classes de vinho')
plt.show()

df.info()

"""## Visualiza√ß√£o das features"""

# Carregar o dataset
wine = load_wine()
df = pd.DataFrame(wine.data, columns=wine.feature_names)

# Gerar matriz de correla√ß√£o
corr_matrix = df.corr()

# Visualizar com heatmap
plt.figure(figsize=(12,10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('üîó Matriz de Correla√ß√£o - Dataset Vinho')
plt.show()

"""Interpreta√ß√£o r√°pida
‚Ä¢ Correla√ß√£o pr√≥xima de 1 ‚Üí forte rela√ß√£o positiva
‚Ä¢ Correla√ß√£o pr√≥xima de -1 ‚Üí forte rela√ß√£o negativa
‚Ä¢ Correla√ß√£o pr√≥xima de 0 ‚Üí pouca ou nenhuma rela√ß√£o

Correla√ß√µes Fortes Positivas (‚Üë)
Essas vari√°veis t√™m alta associa√ß√£o e podem indicar redund√¢ncia ou relev√¢ncia conjunta:
- flavanoids e total_phenols ‚Üí 0.86
‚Üí Flavonoides s√£o um tipo de fenol, ent√£o essa correla√ß√£o √© esperada. Ambas s√£o √≥timas para distinguir tipos de vinho.
- od280/od315_of_diluted_wines e flavanoids ‚Üí 0.79
‚Üí Alta absor√ß√£o √≥ptica est√° ligada √† concentra√ß√£o de flavonoides, o que pode indicar qualidade.
- alcohol e od280/od315_of_diluted_wines ‚Üí 0.72
‚Üí Vinhos com maior teor alco√≥lico tendem a ter maior absor√ß√£o √≥ptica, sugerindo maior concentra√ß√£o de compostos.
- proline e alcohol ‚Üí 0.71
‚Üí Prolina, um amino√°cido, pode estar associada √† matura√ß√£o ou qualidade do vinho.
----------------------------------------------------------------------------
Correla√ß√µes Fortes Negativas (‚Üì)
Essas vari√°veis se movem em dire√ß√µes opostas e podem ajudar a contrastar classes:
- flavanoids e nonflavanoid_phenols ‚Üí ‚àí0.43
‚Üí Rela√ß√£o inversa entre tipos de fen√≥is. Pode indicar equil√≠brio qu√≠mico entre compostos.
- color_intensity e hue ‚Üí ‚àí0.56
‚Üí Vinhos mais intensos em cor tendem a ter tonalidade mais baixa. √ötil para distinguir visualmente os tipos.
----------------------------------------------------------------------------
- Vari√°veis com alta correla√ß√£o positiva podem ser redundantes ‚Üí √∫teis para redu√ß√£o de dimensionalidade com PCA.
- Vari√°veis com boa separa√ß√£o entre classes (como flavanoids, alcohol, od280/od315) s√£o excelentes para modelos de classifica√ß√£o.
- Correla√ß√µes negativas ajudam a contrastar padr√µes entre classes, especialmente em modelos baseados em √°rvores.

## Pr√©-processamento
"""

# Carregar o dataset
wine = load_wine()
df = pd.DataFrame(wine.data, columns=wine.feature_names)
df['target'] = wine.target
df['class'] = df['target'].apply(lambda x: wine.target_names[x])

X = df[wine.feature_names]
y = df['target']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""## Treinar e comparar modelos"""

models = {
    'Logistic Regression': LogisticRegression(max_iter=500),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(),
    'KNN': KNeighborsClassifier()
}

results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    results.append({'Model': name, 'Accuracy': acc})

"""Visualizar desempenho"""

results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)

sns.barplot(x='Accuracy', y='Model', data=results_df)
plt.title('Compara√ß√£o de acur√°cia entre modelos (dataset vinho)')
plt.xlim(0.8, 1.0)
plt.show()

"""## Relat√≥rio de melhor modelo"""

best_model_name = results_df.iloc[0]['Model']
best_model = models[best_model_name]
y_pred = best_model.predict(X_test)

print(f'Melhor modelo: {best_model_name}')
print(classification_report(y_test, y_pred, target_names=wine.target_names))

"""## An√°lise Final"""

# Respostas √†s perguntas
print("‚û°Ô∏è Melhor modelo:", best_model_name)
print("‚û°Ô∏è Classes mais dif√≠ceis de prever: verifique precis√£o e recall no classification_report acima.")
print("‚û°Ô∏è O uso de StandardScaler influenciou os resultados: sim, especialmente para SVM, KNN e Logistic Regression.")